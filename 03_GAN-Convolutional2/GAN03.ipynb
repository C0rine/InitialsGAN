{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional WGAN\n",
    "```GAN 03 - Convolutional with Wasserstein, 64x64 output ```\n",
    "\n",
    "Used Yun Chen's code for reference: https://github.com/chenyuntc/pytorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Set model parameters:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670544354ce04318b3ae3e9da627430c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1817524a23bc4a88b0a38b4e3177320c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb652ca71294474798bb84852e10332a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c63a5912814d1f9e705b94b80927f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c05ef63c62e4bb4b9ece9b9b6b047d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d04af36d18849ad8381164c7325453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e274ee98e2644ccbee3617d2fea12f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074a507c56f5497596187f823850741d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\\* Only relevant in case of use of Wasserstein distance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import UI\n",
    "UI.Show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model settings: ConvolutionalGAN, BCE loss, RMSprop optimizer, BatchNorm, batchsize of 128, learning rate of 0.0007, for 25 epochs.\n",
      "Results to be saved at: Z:/GAN-Training-Results/WConvolutional_64x64_32bs/\n"
     ]
    }
   ],
   "source": [
    "modelsettings = UI.getformattedparms()\n",
    "print('Model settings: ' + modelsettings)\n",
    "print('Results to be saved at: ' + UI.savepath.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2db8126b24d41ac8125a40e509bc648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Runs all the cells below\n"
     ]
    }
   ],
   "source": [
    "UI.showrunmodelbutton()\n",
    "print('* Runs all the cells below')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the dataset class (64x64 images)\n",
    "import dataset02 as dataset\n",
    "\n",
    "# python imports\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 30650 images in this dataset\n"
     ]
    }
   ],
   "source": [
    "# This opens the HDF5 database and allows us to query it\n",
    "data = dataset.get_dataset()\n",
    "print(\"there are\", len(data), \"images in this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting threads (num_workers) to 0 as suggested at https://discuss.pytorch.org/t/dataloader-iteration-hang-up/12886/3\n",
    "threads = 0 # can increase this to have more data preloading, useful if your CPU cant keep up with GPU\n",
    "batchSize = 32\n",
    "shuffle = True # Shuffles the dataset before loading batches\n",
    "cuda = True\n",
    "\n",
    "train_loader = DataLoader(dataset=data, num_workers=threads, batch_size=batchSize, shuffle=shuffle, pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 958 batches\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005 # learning rate\n",
    "noisedim = 100 # noise dimension\n",
    "image_size = 64\n",
    "image_size2 = 64\n",
    "nc = 1 # channel of img \n",
    "ngf = 64 # generate channel\n",
    "ndf = 64 # discriminative channel\n",
    "beta1 = 0.5\n",
    "num_epochs = 50 # =1 when debug\n",
    "num_batches = len(train_loader)\n",
    "clamp_num = 0.75 # WGAN clip gradient\n",
    "\n",
    "print('There are ' + str(num_batches) + ' batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b34fb5bd7672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# For WGAN we remove the sigmoid function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# nn.Sigmoid()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[1;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                 \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "discriminator = nn.Sequential(\n",
    "        nn.Conv2d(nc,ndf,4,2,1,bias=False),\n",
    "        nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf,ndf*2,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ndf*2),\n",
    "        nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf*2,ndf*4,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ndf*4),\n",
    "        nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf*4,ndf*8,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ndf*8),\n",
    "        nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf*8,1,4,1,0,bias=False),\n",
    "        # For WGAN we remove the sigmoid function\n",
    "        # nn.Sigmoid()\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator= nn.Sequential(\n",
    "        nn.ConvTranspose2d(noisedim,ngf*8,4,1,0,bias=False),\n",
    "        nn.BatchNorm2d(ngf*8),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.ConvTranspose2d(ngf*8,ngf*4,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ngf*4),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.ConvTranspose2d(ngf*4,ngf*2,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ngf*2),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.ConvTranspose2d(ngf*2,ngf,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.ConvTranspose2d(ngf,nc,4,2,1,bias=False),\n",
    "        nn.Tanh()\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weigth initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    class_name=m.__class__.__name__\n",
    "    if class_name.find('Conv')!=-1:\n",
    "        m.weight.data.normal_(0,0.02)\n",
    "    elif class_name.find('Norm')!=-1:\n",
    "        m.weight.data.normal_(1.0,0.02)\n",
    "\n",
    "discriminator.apply(weight_init)\n",
    "generator.apply(weight_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = RMSprop(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = RMSprop(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for training\n",
    "one = torch.FloatTensor([1])\n",
    "mone = -1*one\n",
    "\n",
    "one = one.cuda()\n",
    "mone = mone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels):\n",
    "    # train with real images\n",
    "    discriminator.zero_grad()\n",
    "    outputs = discriminator(images)\n",
    "    outputs.backward(one)\n",
    "    \n",
    "    # train with fake images\n",
    "    outputs = discriminator(fake_images) \n",
    "    outputs.backward(mone)\n",
    "    d_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(generator, discriminator_outputs, real_labels):\n",
    "    generator.zero_grad()\n",
    "    discriminator_outputs.backward(one)\n",
    "    g_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw samples from the input distribution to inspect the generation on training \n",
    "num_test_samples = 25\n",
    "fix_noise = Variable(torch.FloatTensor(num_test_samples, noisedim, 1, 1).normal_(0,1)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Working on epoch ' + str(epoch) + ' ...')\n",
    "    for n, (images, letters, countries, cities, names) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda()\n",
    "        real_labels = Variable(torch.ones(images.size(0)).cuda())\n",
    "        \n",
    "        # Generate the noise\n",
    "        noise = torch.randn(images.size(0),noisedim,1,1)\n",
    "        noise = Variable(noise).cuda()\n",
    "        \n",
    "        # clip paramaters for discriminator\n",
    "        for parameter in discriminator.parameters():\n",
    "            parameter.data.clamp_(-clamp_num, clamp_num)\n",
    "        \n",
    "        # Sample from generator using the noise\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = Variable(torch.zeros(images.size(0)).cuda())\n",
    "        \n",
    "        # Train the discriminator\n",
    "        train_discriminator(discriminator, images, real_labels, fake_images, fake_labels)\n",
    "        \n",
    "        # Sample again from the generator and get output from discriminator\n",
    "        noise = torch.randn(images.size(0),noisedim,1,1)\n",
    "        noise = Variable(noise).cuda()\n",
    "        \n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images)\n",
    "        \n",
    "        # Train the generator more often\n",
    "        if (n+1)%5 == 0:\n",
    "            train_generator(generator, outputs, real_labels)\n",
    "            if n%100: pass\n",
    "        \n",
    "        # For every hundred batches show and save a plot of output\n",
    "        if (n+1) % 190 == 0:\n",
    "            step = 0\n",
    "            test_images = generator(fix_noise)\n",
    "            \n",
    "            for k in range(num_test_samples):\n",
    "                i = k//5\n",
    "                j = k%5\n",
    "                ax[i,j].cla()\n",
    "                ax[i,j].imshow(test_images[k,:].data.cpu().numpy().reshape(64, 64), cmap='gray')\n",
    "            display.clear_output(wait=True)\n",
    "            plt.title(\"Epoch \" + str(epoch), y=5.85, x=-1.98)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            plt.savefig('Z:/GAN-Training-Results/WConvolutional_64x64_32bs/result_' + str(epoch+1) + '-' + str(n+1) + '.png')\n",
    "            step += 1\n",
    "            \n",
    "            print('Epoch [%d/%d], Step[%d/%d]' \n",
    "                  %(epoch + 1, num_epochs, n+1, num_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
